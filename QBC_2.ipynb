{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2d6a6197-07e5-4fd0-83ee-d2995d069633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "dev = qml.device(\"default.qubit\")\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c32f3a8-c703-44d9-a726-3289ce94aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 4\n",
    "num_layers = 6\n",
    "@qml.qnode(dev)\n",
    "def circuit(x, weights):\n",
    "    # Angle embedding\n",
    "    # print(\"Input:\",x)\n",
    "    qml.templates.AngleEmbedding(x, wires=range(num_qubits))\n",
    "\n",
    "    # Basic entangler layers\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
    "\n",
    "    # qml.CNOT(wires=[10,0])\n",
    "    # Measurement\n",
    "    return qml.expval(qml.PauliX(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a78b413f-82cf-4417-be25-f847052b899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dacbda74-4fb5-4b7c-b9c9-eaa0e9c25f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, X, Y):\n",
    "    predictions = circuit(X, weights)\n",
    "    \n",
    "    # Sigmoid activation to convert to probabilities\n",
    "    predictions = 1 / (1 + np.exp(-predictions,requires_grad = True))\n",
    "\n",
    "    # Calculate BCE loss\n",
    "    bce_loss = -np.mean(Y * np.log(predictions + 1e-10) + (1 - Y) * np.log(1 - predictions + 1e-10))\n",
    "    return bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc08e09c-b5eb-499b-96c6-5a2f37d62c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " person_age                       0\n",
      "person_income                    0\n",
      "person_home_ownership            0\n",
      "person_emp_length              895\n",
      "loan_intent                      0\n",
      "loan_grade                       0\n",
      "loan_amnt                        0\n",
      "loan_int_rate                 3116\n",
      "loan_status                      0\n",
      "loan_percent_income              0\n",
      "cb_person_default_on_file        0\n",
      "cb_person_cred_hist_length       0\n",
      "dtype: int64\n",
      "X_train: (22910, 4), y_train: (22910,)\n",
      "X_test: (2864, 4), y_test: (2864,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Load the dataset (adjust the path to your file)\n",
    "df = pd.read_csv('credit_risk_dataset.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Preprocessing: Fill or drop missing values as necessary\n",
    "# df.fillna(0, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.select_dtypes(exclude=['object'])\n",
    "# Identify categorical columns\n",
    "# categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical columns\n",
    "# for col in categorical_cols:\n",
    "    # df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop('loan_status', axis=1)  # Replace 'loan_status' with your target variable name\n",
    "# X = X.drop(['person_emp_length', 'person_age'],axis=1)\n",
    "X = X[['person_age','person_income','person_emp_length','loan_amnt']]\n",
    "scaler = MinMaxScaler()\n",
    "X['loan_amnt'] = scaler.fit_transform(X[['loan_amnt']])\n",
    "y = df['loan_status']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test= train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "# print(X_train.iloc[0])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "y_train[y_train==0] = -1\n",
    "y_test[y_test==0] = -1\n",
    "y_val[y_val==0] = -1\n",
    "# print(\"Shapes of the training and test sets:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dcecf74d-2961-4727-a9a7-6e2ede82490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "weights_init = np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "# bias_init = np.array(0.0, requires_grad=True)\n",
    "#\n",
    "# print(\"Weights:\", weights_init)\n",
    "# print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5553fea5-d392-412e-a156-2b68af6efc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RX(-0.43)──Rot(1.76,0.40,0.98)───╭●───────╭X──Rot(0.76,0.12,0.44)───╭●────╭X\n",
      "1: ──RX(0.59)───Rot(2.24,1.87,-0.98)──╰X─╭●────│───Rot(0.33,1.49,-0.21)──│──╭●─│─\n",
      "2: ──RX(-0.67)──Rot(0.95,-0.15,-0.10)────╰X─╭●─│───Rot(0.31,-0.85,-2.55)─╰X─│──╰●\n",
      "3: ──RX(-0.01)──Rot(0.41,0.14,1.45)─────────╰X─╰●──Rot(0.65,0.86,-0.74)─────╰X───\n",
      "\n",
      "───Rot(2.27,-1.45,0.05)────────────────────────╭●─╭X──Rot(1.23,1.20,-0.39)────────────────────────\n",
      "──╭X─────────────────────Rot(-0.19,1.53,1.47)──│──╰●─╭X─────────────────────Rot(-0.30,-1.05,-1.42)\n",
      "──│──────────────────────Rot(0.15,0.38,-0.89)──│─────╰●────────────────────╭X─────────────────────\n",
      "──╰●─────────────────────Rot(-1.98,-0.35,0.16)─╰X──────────────────────────╰●─────────────────────\n",
      "\n",
      "──╭●───────────────────────────╭X──Rot(-1.61,-0.21,-0.90)─╭●────╭X──Rot(-0.67,-0.36,-0.81)\n",
      "──╰X─────────────────────╭●────│───Rot(0.39,-0.51,-1.18)──│──╭●─│──╭X─────────────────────\n",
      "───Rot(-1.71,1.95,-0.51)─╰X─╭●─│───Rot(-0.03,0.43,0.07)───╰X─│──╰●─│──────────────────────\n",
      "───Rot(-0.44,-1.25,0.78)────╰X─╰●──Rot(0.30,-0.63,-0.36)─────╰X────╰●─────────────────────\n",
      "\n",
      "─────────────────────────╭●─╭X───────┤  <X>\n",
      "───Rot(-1.73,0.18,-0.40)─│──╰●─╭X────┤     \n",
      "───Rot(-1.63,0.46,-0.91)─│─────╰●─╭X─┤     \n",
      "───Rot(0.05,0.73,0.13)───╰X───────╰●─┤     \n",
      "[-0.43340234  0.58547569 -0.66894316 -0.00936358]\n"
     ]
    }
   ],
   "source": [
    "circuit_draw = qml.draw(circuit,level=\"device\")(X_train[0], weights_init)  # Visualize with the first training sample\n",
    "print(circuit_draw)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9722450f-0f35-4a7a-a6ed-354c341f3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    1 | Cost: 0.6350787 | Accuracy: 0.5625000 | Val_Accuracy: 0.4687500\n",
      "Iter:   11 | Cost: 0.5262793 | Accuracy: 0.5937500 | Val_Accuracy: 0.7500000\n",
      "Iter:   21 | Cost: 0.2812967 | Accuracy: 0.6875000 | Val_Accuracy: 0.7500000\n",
      "Iter:   31 | Cost: 0.0303416 | Accuracy: 0.8437500 | Val_Accuracy: 0.7812500\n",
      "Iter:   41 | Cost: 0.2677883 | Accuracy: 0.6250000 | Val_Accuracy: 0.9687500\n",
      "Iter:   51 | Cost: 0.0250283 | Accuracy: 0.8125000 | Val_Accuracy: 0.7500000\n",
      "Iter:   61 | Cost: 0.0993236 | Accuracy: 0.7500000 | Val_Accuracy: 0.7500000\n",
      "Iter:   71 | Cost: 0.0890100 | Accuracy: 0.7187500 | Val_Accuracy: 0.6250000\n",
      "Iter:   81 | Cost: 0.0104861 | Accuracy: 0.8125000 | Val_Accuracy: 0.7812500\n",
      "Iter:   91 | Cost: 0.2361662 | Accuracy: 0.6562500 | Val_Accuracy: 0.7812500\n",
      "Iter:  101 | Cost: -0.1551433 | Accuracy: 0.9062500 | Val_Accuracy: 0.7812500\n",
      "Iter:  111 | Cost: -0.0101629 | Accuracy: 0.7500000 | Val_Accuracy: 0.6562500\n",
      "Iter:  121 | Cost: 0.1694456 | Accuracy: 0.7187500 | Val_Accuracy: 0.7187500\n",
      "Iter:  131 | Cost: -0.2485345 | Accuracy: 0.8750000 | Val_Accuracy: 0.7500000\n",
      "Iter:  141 | Cost: 0.0697901 | Accuracy: 0.7500000 | Val_Accuracy: 0.5937500\n",
      "Iter:  151 | Cost: 0.0523889 | Accuracy: 0.6875000 | Val_Accuracy: 0.8125000\n",
      "Iter:  161 | Cost: -0.1248590 | Accuracy: 0.8125000 | Val_Accuracy: 0.9062500\n",
      "Iter:  171 | Cost: -0.0915228 | Accuracy: 0.8125000 | Val_Accuracy: 0.8437500\n",
      "Iter:  181 | Cost: 0.0041298 | Accuracy: 0.7187500 | Val_Accuracy: 0.7812500\n",
      "Iter:  191 | Cost: 0.0530471 | Accuracy: 0.6875000 | Val_Accuracy: 0.7812500\n",
      "Iter:  201 | Cost: -0.2262834 | Accuracy: 0.8437500 | Val_Accuracy: 0.5937500\n",
      "Iter:  211 | Cost: -0.0555724 | Accuracy: 0.8125000 | Val_Accuracy: 0.7812500\n",
      "Iter:  221 | Cost: 0.0209342 | Accuracy: 0.7500000 | Val_Accuracy: 0.8437500\n",
      "Iter:  231 | Cost: 0.0312372 | Accuracy: 0.6875000 | Val_Accuracy: 0.8125000\n",
      "Iter:  241 | Cost: 0.0675577 | Accuracy: 0.6875000 | Val_Accuracy: 0.7187500\n",
      "Iter:  251 | Cost: -0.1742936 | Accuracy: 0.8125000 | Val_Accuracy: 0.7187500\n",
      "Iter:  261 | Cost: -0.1967271 | Accuracy: 0.8750000 | Val_Accuracy: 0.8125000\n",
      "Iter:  271 | Cost: -0.0449661 | Accuracy: 0.8125000 | Val_Accuracy: 0.7500000\n",
      "Iter:  281 | Cost: -0.0676428 | Accuracy: 0.8125000 | Val_Accuracy: 0.5625000\n",
      "Iter:  291 | Cost: -0.0442676 | Accuracy: 0.8125000 | Val_Accuracy: 0.7187500\n",
      "Iter:  301 | Cost: -0.0204977 | Accuracy: 0.8125000 | Val_Accuracy: 0.8437500\n",
      "Iter:  311 | Cost: -0.1988606 | Accuracy: 0.8750000 | Val_Accuracy: 0.8437500\n",
      "Iter:  321 | Cost: -0.1620870 | Accuracy: 0.8750000 | Val_Accuracy: 0.7500000\n",
      "Iter:  331 | Cost: 0.0277352 | Accuracy: 0.7187500 | Val_Accuracy: 0.9062500\n",
      "Iter:  341 | Cost: -0.1227179 | Accuracy: 0.7812500 | Val_Accuracy: 0.6875000\n",
      "Iter:  351 | Cost: -0.1409185 | Accuracy: 0.8125000 | Val_Accuracy: 0.7500000\n",
      "Iter:  361 | Cost: -0.0027263 | Accuracy: 0.6875000 | Val_Accuracy: 0.7187500\n",
      "Iter:  371 | Cost: 0.0117222 | Accuracy: 0.7187500 | Val_Accuracy: 0.7812500\n",
      "Iter:  381 | Cost: 0.0492995 | Accuracy: 0.7187500 | Val_Accuracy: 0.6875000\n",
      "Iter:  391 | Cost: -0.0757254 | Accuracy: 0.7812500 | Val_Accuracy: 0.7500000\n",
      "Iter:  401 | Cost: -0.0072984 | Accuracy: 0.7187500 | Val_Accuracy: 0.8437500\n",
      "Iter:  411 | Cost: -0.1016884 | Accuracy: 0.7812500 | Val_Accuracy: 0.7500000\n",
      "Iter:  421 | Cost: -0.1188312 | Accuracy: 0.8125000 | Val_Accuracy: 0.8437500\n",
      "Iter:  431 | Cost: -0.0058327 | Accuracy: 0.7187500 | Val_Accuracy: 0.8125000\n",
      "Iter:  441 | Cost: 0.0125519 | Accuracy: 0.7187500 | Val_Accuracy: 0.9062500\n",
      "Iter:  451 | Cost: -0.3206890 | Accuracy: 0.9062500 | Val_Accuracy: 0.8437500\n",
      "Iter:  461 | Cost: -0.1593424 | Accuracy: 0.8125000 | Val_Accuracy: 0.7187500\n",
      "Iter:  471 | Cost: 0.0274651 | Accuracy: 0.6875000 | Val_Accuracy: 0.8125000\n",
      "Iter:  481 | Cost: -0.1235397 | Accuracy: 0.7812500 | Val_Accuracy: 0.8437500\n",
      "Iter:  491 | Cost: -0.0055452 | Accuracy: 0.7500000 | Val_Accuracy: 0.7812500\n",
      "Iter:  501 | Cost: -0.0615340 | Accuracy: 0.8125000 | Val_Accuracy: 0.7812500\n",
      "Iter:  511 | Cost: -0.0838104 | Accuracy: 0.8125000 | Val_Accuracy: 0.7187500\n",
      "Iter:  521 | Cost: -0.1830595 | Accuracy: 0.8437500 | Val_Accuracy: 0.6562500\n",
      "Iter:  531 | Cost: 0.1734981 | Accuracy: 0.6250000 | Val_Accuracy: 0.7187500\n",
      "Iter:  541 | Cost: -0.4312010 | Accuracy: 0.9687500 | Val_Accuracy: 0.8125000\n",
      "Iter:  551 | Cost: 0.0003644 | Accuracy: 0.7500000 | Val_Accuracy: 0.7187500\n",
      "Iter:  561 | Cost: 0.0329923 | Accuracy: 0.7187500 | Val_Accuracy: 0.7187500\n",
      "Iter:  571 | Cost: -0.1833673 | Accuracy: 0.8437500 | Val_Accuracy: 0.8125000\n",
      "Iter:  581 | Cost: -0.1545798 | Accuracy: 0.8437500 | Val_Accuracy: 0.7812500\n",
      "Iter:  591 | Cost: -0.1029421 | Accuracy: 0.7500000 | Val_Accuracy: 0.7187500\n",
      "Iter:  601 | Cost: 0.0362859 | Accuracy: 0.7187500 | Val_Accuracy: 0.5312500\n",
      "Iter:  611 | Cost: -0.4146135 | Accuracy: 0.9375000 | Val_Accuracy: 0.8125000\n",
      "Iter:  621 | Cost: -0.2230148 | Accuracy: 0.8437500 | Val_Accuracy: 0.8437500\n",
      "Iter:  631 | Cost: 0.0063584 | Accuracy: 0.7500000 | Val_Accuracy: 0.8125000\n",
      "Iter:  641 | Cost: -0.1215955 | Accuracy: 0.8125000 | Val_Accuracy: 0.5937500\n",
      "Iter:  651 | Cost: -0.1751357 | Accuracy: 0.8125000 | Val_Accuracy: 0.7812500\n",
      "Iter:  661 | Cost: 0.0200092 | Accuracy: 0.7187500 | Val_Accuracy: 0.6250000\n",
      "Iter:  671 | Cost: -0.0857838 | Accuracy: 0.7500000 | Val_Accuracy: 0.6562500\n",
      "Iter:  681 | Cost: -0.1738904 | Accuracy: 0.8125000 | Val_Accuracy: 0.7187500\n",
      "Iter:  691 | Cost: -0.0370180 | Accuracy: 0.7187500 | Val_Accuracy: 0.7500000\n",
      "Iter:  701 | Cost: 0.0989774 | Accuracy: 0.6562500 | Val_Accuracy: 0.6562500\n",
      "Iter:  711 | Cost: -0.0138989 | Accuracy: 0.7500000 | Val_Accuracy: 0.8125000\n",
      "Iter:  721 | Cost: 0.0750413 | Accuracy: 0.6875000 | Val_Accuracy: 0.9062500\n",
      "Iter:  731 | Cost: -0.0277166 | Accuracy: 0.7812500 | Val_Accuracy: 0.6875000\n",
      "Iter:  741 | Cost: -0.2675616 | Accuracy: 0.8437500 | Val_Accuracy: 0.7500000\n",
      "Iter:  751 | Cost: -0.0703631 | Accuracy: 0.7187500 | Val_Accuracy: 0.7187500\n",
      "Iter:  761 | Cost: 0.0818970 | Accuracy: 0.6562500 | Val_Accuracy: 0.8437500\n",
      "Iter:  771 | Cost: -0.2235214 | Accuracy: 0.8437500 | Val_Accuracy: 0.7500000\n",
      "Iter:  781 | Cost: -0.1843675 | Accuracy: 0.8437500 | Val_Accuracy: 0.6562500\n",
      "Iter:  791 | Cost: -0.0859233 | Accuracy: 0.7500000 | Val_Accuracy: 0.7812500\n",
      "Iter:  801 | Cost: -0.2274875 | Accuracy: 0.8437500 | Val_Accuracy: 0.7500000\n",
      "Iter:  811 | Cost: -0.0381581 | Accuracy: 0.7500000 | Val_Accuracy: 0.6875000\n",
      "Iter:  821 | Cost: -0.1998176 | Accuracy: 0.8125000 | Val_Accuracy: 0.8750000\n",
      "Iter:  831 | Cost: -0.0456997 | Accuracy: 0.7187500 | Val_Accuracy: 0.8125000\n",
      "Iter:  841 | Cost: -0.0793557 | Accuracy: 0.7812500 | Val_Accuracy: 0.7500000\n",
      "Iter:  851 | Cost: -0.1941613 | Accuracy: 0.8750000 | Val_Accuracy: 0.6875000\n",
      "Iter:  861 | Cost: -0.0079575 | Accuracy: 0.7187500 | Val_Accuracy: 0.7500000\n",
      "Iter:  871 | Cost: -0.2076594 | Accuracy: 0.8437500 | Val_Accuracy: 0.7187500\n",
      "Iter:  881 | Cost: -0.0323778 | Accuracy: 0.7500000 | Val_Accuracy: 0.7500000\n",
      "Iter:  891 | Cost: 0.0825742 | Accuracy: 0.6875000 | Val_Accuracy: 0.7187500\n",
      "Iter:  901 | Cost: -0.1290179 | Accuracy: 0.8125000 | Val_Accuracy: 0.7500000\n",
      "Iter:  911 | Cost: -0.0178380 | Accuracy: 0.7500000 | Val_Accuracy: 0.6875000\n",
      "Iter:  921 | Cost: -0.2682271 | Accuracy: 0.8750000 | Val_Accuracy: 0.7500000\n",
      "Iter:  931 | Cost: 0.1513420 | Accuracy: 0.6562500 | Val_Accuracy: 0.6875000\n",
      "Iter:  941 | Cost: -0.0898909 | Accuracy: 0.7500000 | Val_Accuracy: 0.8125000\n",
      "Iter:  951 | Cost: 0.1330684 | Accuracy: 0.6875000 | Val_Accuracy: 0.6562500\n",
      "Iter:  961 | Cost: -0.1801372 | Accuracy: 0.8437500 | Val_Accuracy: 0.8437500\n",
      "Iter:  971 | Cost: 0.0177139 | Accuracy: 0.6875000 | Val_Accuracy: 0.6875000\n",
      "Iter:  981 | Cost: -0.0805901 | Accuracy: 0.7812500 | Val_Accuracy: 0.6875000\n",
      "Iter:  991 | Cost: -0.1014663 | Accuracy: 0.7812500 | Val_Accuracy: 0.7187500\n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "# bias = bias_init\n",
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 32\n",
    "costs = []\n",
    "for it in range(1000):\n",
    "\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    batch_index_val = np.random.randint(0, len(X_val), (batch_size,))\n",
    "    X_batch = X_train[batch_index]\n",
    "    # print(X_batch)\n",
    "    Y_batch = y_train[batch_index]\n",
    "\n",
    "    X_val_b = X_val[ batch_index_val]\n",
    "    Y_val_b = y_val[ batch_index_val]\n",
    "    \n",
    "    # print(Y_batch)\n",
    "    weights= opt.step(cost, weights,  X=X_batch, Y=Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(circuit(x,  weights)) for x in X_batch]\n",
    "    # print(predictions)\n",
    "    # print(Y_batch)\n",
    "    current_cost = cost(weights,  X_batch, Y_batch)\n",
    "    costs.append(current_cost)\n",
    "    acc = accuracy(Y_batch, predictions)\n",
    "    \n",
    "    predictions = [np.sign(circuit(x,  weights)) for x in X_val_b]\n",
    "    val_acc =accuracy(Y_val_b, predictions)\n",
    "\n",
    "    if it%10 == 0:\n",
    "        print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f} | Val_Accuracy: {val_acc:0.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "42d84243-c41f-42fa-8408-889d4d904b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.sign(circuit(x,  weights)) for x in X_test]\n",
    "acc = accuracy(y_test, predictions)\n",
    "report = classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "edecc40b-1061-4b82-92eb-36913a13bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772695530726257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.99      0.87      2238\n",
      "           1       0.16      0.01      0.02       626\n",
      "\n",
      "    accuracy                           0.77      2864\n",
      "   macro avg       0.47      0.50      0.44      2864\n",
      "weighted avg       0.65      0.77      0.68      2864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d51752f5-315b-460b-a3fd-423c0f797457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.99      0.88      2238\n",
      "           1       0.62      0.08      0.14       626\n",
      "\n",
      "    accuracy                           0.79      2864\n",
      "   macro avg       0.71      0.53      0.51      2864\n",
      "weighted avg       0.75      0.79      0.72      2864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40739cb5-5af5-483c-b979-34f339de3745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8083100558659218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b93c01-d39d-4401-b783-9d889d001b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
