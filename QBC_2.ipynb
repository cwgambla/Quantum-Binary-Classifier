{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d6a6197-07e5-4fd0-83ee-d2995d069633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "dev = qml.device(\"default.qubit\")\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9c32f3a8-c703-44d9-a726-3289ce94aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "num_layers = 4\n",
    "@qml.qnode(dev)\n",
    "def circuit(x, weights):\n",
    "    # Angle embedding\n",
    "    # print(\"Input:\",x)\n",
    "    qml.templates.AngleEmbedding(x, wires=range(num_qubits))\n",
    "\n",
    "    # Basic entangler layers\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
    "\n",
    "    # qml.CNOT(wires=[10,0])\n",
    "    # Measurement\n",
    "    return qml.expval(qml.PauliX(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a78b413f-82cf-4417-be25-f847052b899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dacbda74-4fb5-4b7c-b9c9-eaa0e9c25f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, X, Y):\n",
    "    predictions = circuit(X, weights)\n",
    "    \n",
    "    # Sigmoid activation to convert to probabilities\n",
    "    predictions = 1 / (1 + np.exp(-predictions,requires_grad = True))\n",
    "\n",
    "    # Calculate BCE loss\n",
    "    bce_loss = -np.mean(Y * np.log(predictions + 1e-10) + (1 - Y) * np.log(1 - predictions + 1e-10))\n",
    "    return bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc08e09c-b5eb-499b-96c6-5a2f37d62c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " person_age                       0\n",
      "person_income                    0\n",
      "person_home_ownership            0\n",
      "person_emp_length              895\n",
      "loan_intent                      0\n",
      "loan_grade                       0\n",
      "loan_amnt                        0\n",
      "loan_int_rate                 3116\n",
      "loan_status                      0\n",
      "loan_percent_income              0\n",
      "cb_person_default_on_file        0\n",
      "cb_person_cred_hist_length       0\n",
      "dtype: int64\n",
      "X_train: (22910, 3), y_train: (22910,)\n",
      "X_test: (2864, 3), y_test: (2864,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset (adjust the path to your file)\n",
    "df = pd.read_csv('credit_risk_dataset.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Preprocessing: Fill or drop missing values as necessary\n",
    "# df.fillna(0, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.select_dtypes(exclude=['object'])\n",
    "# Identify categorical columns\n",
    "# categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical columns\n",
    "# for col in categorical_cols:\n",
    "    # df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop('loan_status', axis=1)  # Replace 'loan_status' with your target variable name\n",
    "# X = X.drop(['person_emp_length', 'person_age'],axis=1)\n",
    "X = X[['person_age','person_income','person_emp_length']]\n",
    "y = df['loan_status']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test= train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "# print(X_train.iloc[0])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "y_train[y_train==0] = -1\n",
    "y_test[y_test==0] = -1\n",
    "y_val[y_val==0] = -1\n",
    "# print(\"Shapes of the training and test sets:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dcecf74d-2961-4727-a9a7-6e2ede82490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "weights_init = np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "# bias_init = np.array(0.0, requires_grad=True)\n",
    "#\n",
    "# print(\"Weights:\", weights_init)\n",
    "# print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5553fea5-d392-412e-a156-2b68af6efc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RX(-0.43)──Rot(1.76,0.40,0.98)───╭●────╭X──Rot(0.41,0.14,1.45)──╭●─╭X──Rot(0.31,-0.85,-2.55)\n",
      "1: ──RX(0.59)───Rot(2.24,1.87,-0.98)──╰X─╭●─│───Rot(0.76,0.12,0.44)──│──╰●─╭X────────────────────\n",
      "2: ──RX(-0.67)──Rot(0.95,-0.15,-0.10)────╰X─╰●──Rot(0.33,1.49,-0.21)─╰X────╰●────────────────────\n",
      "\n",
      "────────────────────────╭●────╭X──Rot(-0.19,1.53,1.47)──╭●─╭X────┤  <X>\n",
      "───Rot(0.65,0.86,-0.74)─╰X─╭●─│───Rot(0.15,0.38,-0.89)──│──╰●─╭X─┤     \n",
      "───Rot(2.27,-1.45,0.05)────╰X─╰●──Rot(-1.98,-0.35,0.16)─╰X────╰●─┤     \n",
      "[-0.43340234  0.58547569 -0.66894316]\n"
     ]
    }
   ],
   "source": [
    "circuit_draw = qml.draw(circuit,level=\"device\")(X_train[0], weights_init)  # Visualize with the first training sample\n",
    "print(circuit_draw)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9722450f-0f35-4a7a-a6ed-354c341f3d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    1 | Cost: 0.7699111 | Accuracy: 0.3750000\n",
      "Iter:   11 | Cost: 0.3270239 | Accuracy: 0.8125000\n",
      "Iter:   21 | Cost: 0.1404438 | Accuracy: 0.8125000\n",
      "Iter:   31 | Cost: 0.2430893 | Accuracy: 0.6562500\n",
      "Iter:   41 | Cost: 0.0660526 | Accuracy: 0.7500000\n",
      "Iter:   51 | Cost: 0.0721625 | Accuracy: 0.7187500\n",
      "Iter:   61 | Cost: -0.0003898 | Accuracy: 0.8125000\n",
      "Iter:   71 | Cost: 0.1036998 | Accuracy: 0.6875000\n",
      "Iter:   81 | Cost: 0.0855872 | Accuracy: 0.7187500\n",
      "Iter:   91 | Cost: 0.0297616 | Accuracy: 0.7500000\n",
      "Iter:  101 | Cost: -0.0040487 | Accuracy: 0.7500000\n",
      "Iter:  111 | Cost: -0.0986129 | Accuracy: 0.8125000\n",
      "Iter:  121 | Cost: -0.2253760 | Accuracy: 0.8750000\n",
      "Iter:  131 | Cost: -0.1247283 | Accuracy: 0.7812500\n",
      "Iter:  141 | Cost: -0.0269018 | Accuracy: 0.7500000\n",
      "Iter:  151 | Cost: -0.1402913 | Accuracy: 0.8437500\n",
      "Iter:  161 | Cost: -0.0603833 | Accuracy: 0.7500000\n",
      "Iter:  171 | Cost: -0.1021917 | Accuracy: 0.8125000\n",
      "Iter:  181 | Cost: -0.1070847 | Accuracy: 0.7812500\n",
      "Iter:  191 | Cost: -0.0226943 | Accuracy: 0.7500000\n",
      "Iter:  201 | Cost: -0.0948343 | Accuracy: 0.7500000\n",
      "Iter:  211 | Cost: 0.1638973 | Accuracy: 0.6250000\n",
      "Iter:  221 | Cost: 0.0444704 | Accuracy: 0.6875000\n",
      "Iter:  231 | Cost: -0.0352091 | Accuracy: 0.7187500\n",
      "Iter:  241 | Cost: -0.2647862 | Accuracy: 0.8750000\n",
      "Iter:  251 | Cost: -0.1141277 | Accuracy: 0.7812500\n",
      "Iter:  261 | Cost: -0.2541000 | Accuracy: 0.8437500\n",
      "Iter:  271 | Cost: -0.1348645 | Accuracy: 0.8125000\n",
      "Iter:  281 | Cost: -0.1672735 | Accuracy: 0.8437500\n",
      "Iter:  291 | Cost: -0.0782800 | Accuracy: 0.7500000\n",
      "Iter:  301 | Cost: -0.1914606 | Accuracy: 0.7812500\n",
      "Iter:  311 | Cost: 0.0429971 | Accuracy: 0.6562500\n",
      "Iter:  321 | Cost: 0.0740985 | Accuracy: 0.6562500\n",
      "Iter:  331 | Cost: -0.0188397 | Accuracy: 0.7187500\n",
      "Iter:  341 | Cost: -0.1071764 | Accuracy: 0.7500000\n",
      "Iter:  351 | Cost: -0.0336234 | Accuracy: 0.7187500\n",
      "Iter:  361 | Cost: -0.1085138 | Accuracy: 0.7500000\n",
      "Iter:  371 | Cost: -0.3787833 | Accuracy: 0.9375000\n",
      "Iter:  381 | Cost: -0.5440829 | Accuracy: 1.0000000\n",
      "Iter:  391 | Cost: -0.2916351 | Accuracy: 0.8750000\n",
      "Iter:  401 | Cost: -0.2086349 | Accuracy: 0.8125000\n",
      "Iter:  411 | Cost: -0.2716241 | Accuracy: 0.8750000\n",
      "Iter:  421 | Cost: -0.0643132 | Accuracy: 0.7500000\n",
      "Iter:  431 | Cost: -0.1513632 | Accuracy: 0.8125000\n",
      "Iter:  441 | Cost: -0.3222692 | Accuracy: 0.8437500\n",
      "Iter:  451 | Cost: -0.2438309 | Accuracy: 0.8125000\n",
      "Iter:  461 | Cost: -0.1720588 | Accuracy: 0.7812500\n",
      "Iter:  471 | Cost: -0.1500436 | Accuracy: 0.7812500\n",
      "Iter:  481 | Cost: -0.2644414 | Accuracy: 0.8750000\n",
      "Iter:  491 | Cost: -0.1036007 | Accuracy: 0.7500000\n",
      "Iter:  501 | Cost: -0.0848655 | Accuracy: 0.7187500\n",
      "Iter:  511 | Cost: -0.1007751 | Accuracy: 0.7500000\n",
      "Iter:  521 | Cost: -0.1717287 | Accuracy: 0.7812500\n",
      "Iter:  531 | Cost: -0.0797138 | Accuracy: 0.7500000\n",
      "Iter:  541 | Cost: 0.0477484 | Accuracy: 0.6875000\n",
      "Iter:  551 | Cost: -0.1856001 | Accuracy: 0.7812500\n",
      "Iter:  561 | Cost: -0.0105614 | Accuracy: 0.7187500\n",
      "Iter:  571 | Cost: -0.0982944 | Accuracy: 0.7500000\n",
      "Iter:  581 | Cost: -0.0643476 | Accuracy: 0.7187500\n",
      "Iter:  591 | Cost: 0.1792850 | Accuracy: 0.5937500\n",
      "Iter:  601 | Cost: -0.2344320 | Accuracy: 0.8125000\n",
      "Iter:  611 | Cost: -0.2437120 | Accuracy: 0.8125000\n",
      "Iter:  621 | Cost: -0.1714789 | Accuracy: 0.7812500\n",
      "Iter:  631 | Cost: -0.2854040 | Accuracy: 0.8437500\n",
      "Iter:  641 | Cost: -0.2187218 | Accuracy: 0.8125000\n",
      "Iter:  651 | Cost: 0.0101629 | Accuracy: 0.7187500\n",
      "Iter:  661 | Cost: 0.0460121 | Accuracy: 0.6562500\n",
      "Iter:  671 | Cost: -0.3462351 | Accuracy: 0.9062500\n",
      "Iter:  681 | Cost: -0.3455037 | Accuracy: 0.8750000\n",
      "Iter:  691 | Cost: -0.1137991 | Accuracy: 0.7812500\n",
      "Iter:  701 | Cost: -0.1707555 | Accuracy: 0.8125000\n",
      "Iter:  711 | Cost: -0.2777613 | Accuracy: 0.8125000\n",
      "Iter:  721 | Cost: -0.0815805 | Accuracy: 0.7187500\n",
      "Iter:  731 | Cost: -0.0714811 | Accuracy: 0.7500000\n",
      "Iter:  741 | Cost: -0.2523841 | Accuracy: 0.8437500\n",
      "Iter:  751 | Cost: -0.0771938 | Accuracy: 0.7500000\n",
      "Iter:  761 | Cost: -0.1974543 | Accuracy: 0.7812500\n",
      "Iter:  771 | Cost: -0.2779197 | Accuracy: 0.8437500\n",
      "Iter:  781 | Cost: -0.1958670 | Accuracy: 0.7812500\n",
      "Iter:  791 | Cost: -0.1113034 | Accuracy: 0.7187500\n",
      "Iter:  801 | Cost: -0.2835121 | Accuracy: 0.8125000\n",
      "Iter:  811 | Cost: -0.2619765 | Accuracy: 0.8125000\n",
      "Iter:  821 | Cost: -0.3681955 | Accuracy: 0.8750000\n",
      "Iter:  831 | Cost: -0.1536343 | Accuracy: 0.7500000\n",
      "Iter:  841 | Cost: -0.3307988 | Accuracy: 0.8437500\n",
      "Iter:  851 | Cost: -0.2388362 | Accuracy: 0.8125000\n",
      "Iter:  861 | Cost: 0.0026290 | Accuracy: 0.6875000\n",
      "Iter:  871 | Cost: -0.1095174 | Accuracy: 0.7500000\n",
      "Iter:  881 | Cost: -0.4394026 | Accuracy: 0.9062500\n",
      "Iter:  891 | Cost: -0.3542449 | Accuracy: 0.8437500\n",
      "Iter:  901 | Cost: -0.2270790 | Accuracy: 0.8125000\n",
      "Iter:  911 | Cost: -0.3219706 | Accuracy: 0.8437500\n",
      "Iter:  921 | Cost: -0.3161496 | Accuracy: 0.8437500\n",
      "Iter:  931 | Cost: -0.4139733 | Accuracy: 0.9062500\n",
      "Iter:  941 | Cost: 0.0341018 | Accuracy: 0.6875000\n",
      "Iter:  951 | Cost: -0.2260198 | Accuracy: 0.8125000\n",
      "Iter:  961 | Cost: -0.2575629 | Accuracy: 0.8125000\n",
      "Iter:  971 | Cost: -0.2368450 | Accuracy: 0.8125000\n",
      "Iter:  981 | Cost: -0.2114622 | Accuracy: 0.7812500\n",
      "Iter:  991 | Cost: 0.1490053 | Accuracy: 0.6562500\n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "# bias = bias_init\n",
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 32\n",
    "costs = []\n",
    "for it in range(1000):\n",
    "\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    # batch_index_val = np.random.randint(0, len(X_val), (batch_size,))\n",
    "    X_batch = X_train[batch_index]\n",
    "    # print(X_batch)\n",
    "    Y_batch = y_train[batch_index]\n",
    "\n",
    "    # X_val_b = X_val[ batch_index_val]\n",
    "    # Y_val_b = y_val[ batch_index_val]\n",
    "    \n",
    "    # print(Y_batch)\n",
    "    weights= opt.step(cost, weights,  X=X_batch, Y=Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(circuit(x,  weights)) for x in X_batch]\n",
    "    # print(predictions)\n",
    "    # print(Y_batch)\n",
    "    current_cost = cost(weights,  X_batch, Y_batch)\n",
    "    costs.append(current_cost)\n",
    "    acc = accuracy(Y_batch, predictions)\n",
    "    \n",
    "    # predictions = [np.sign(circuit(x,  weights)) for x in X_val_b]\n",
    "    # val_acc =accuracy(Y_val_b, predictions)\n",
    "\n",
    "    if it%10 == 0:\n",
    "        print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42d84243-c41f-42fa-8408-889d4d904b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.sign(circuit(x,  weights)) for x in X_test]\n",
    "acc = accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "edecc40b-1061-4b82-92eb-36913a13bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692039106145251\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d51752f5-315b-460b-a3fd-423c0f797457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      1.00      0.88      2238\n",
      "           1       0.00      0.00      0.00       626\n",
      "\n",
      "    accuracy                           0.78      2864\n",
      "   macro avg       0.39      0.50      0.44      2864\n",
      "weighted avg       0.61      0.78      0.69      2864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cgamb\\.conda\\envs\\Quantum\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cgamb\\.conda\\envs\\Quantum\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cgamb\\.conda\\envs\\Quantum\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40739cb5-5af5-483c-b979-34f339de3745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7849162011173184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b93c01-d39d-4401-b783-9d889d001b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
